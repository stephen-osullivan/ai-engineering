{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNPpn0YKSgONYf1H7sDhMR2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephen-osullivan/ai-engineering/blob/main/hf_pipelines_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_crIxssuDWac"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "# a pipeline is a combination of a preprocessor (e.g. tokenizer) and a model\n",
        "classifier = pipeline(model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "classifier(\"This movie is disgustingly good !\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oracle = pipeline(model=\"facebook/bart-large-mnli\")\n",
        "oracle(\n",
        "    \"I have a problem with my iphone that needs to be resolved asap!!\",\n",
        "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
        ")"
      ],
      "metadata": {
        "id": "q9hXJfLXERfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kokoro>=0.9.2 soundfile\n",
        "!apt-get -qq -y install espeak-ng > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "iIASYlQGHfgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# audio models tend to use bespoke packages: https://huggingface.co/hexgrad/Kokoro-82M\n",
        "# kokoro voices: https://huggingface.co/hexgrad/Kokoro-82M/blob/main/VOICES.md\n",
        "from kokoro import KPipeline\n",
        "from IPython.display import display, Audio\n",
        "import soundfile as sf\n",
        "import torch\n",
        "pipeline = KPipeline(lang_code='a')\n",
        "text = '''\n",
        "[Kokoro](/kˈOkəɹO/) is an open-weight TTS model with 82 million parameters. Despite its lightweight architecture, it delivers comparable quality to larger models while being significantly faster and more cost-efficient.\n",
        "With Apache-licensed weights, [Kokoro](/kˈOkəɹO/) can be deployed anywhere from production environments to personal projects.\n",
        "'''\n",
        "generator = pipeline(text, voice='af_heart')\n",
        "for i, (gs, ps, audio) in enumerate(generator):\n",
        "    print(i, gs, ps)\n",
        "    display(Audio(data=audio, rate=24000, autoplay=i==0))\n",
        "    sf.write(f'{i}.wav', audio, 24000)"
      ],
      "metadata": {
        "id": "fvQd0A3tEk8Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}